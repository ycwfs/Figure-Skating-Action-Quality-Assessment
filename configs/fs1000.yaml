dataset_name: fs1000
train_split: [training]
val_split: [validation]
devices: ["cuda:0"]
dataset: {
  annotation_folder: /data1/code/datasets/fs/fs1000/,
  vid_feat_folder: /data1/code/datasets/fs/fs1000/i3d,
  aud_feat_folder: /data1/code/datasets/fs/fs1000/vggish,
  file_prefix: None,
  file_ext: .npy,
  max_score: 22,
  num_classes: 24,
  # class path
  class_path: /data1/code/datasets/fs/finefs/24_class.json,
  input_dim: 1024,
  feat_stride: 24,
  num_frames: 24, 
  default_fps: 24,
  trunc_thresh: 0.5,
  crop_ratio: [0.9, 1.0],
  # upsample the features to a fixed length of 192 96
  max_seq_len: 288,
  force_upsampling: True,
  element_numbers: 12, # short program 7, free skate 12
}
model: {
  fpn_type: identity,
  max_buffer_len_factor: 1.0,
  # mha window size for each level, -1 means no mha
  n_mha_win_size: [7, 7, 7, 7, 7, -1],
  # shrink the model for reduced input feature channels
  n_head: 4,
  embd_dim: 512,
  fpn_dim: 512,
  head_dim: 512,
  use_abs_pe: True,
}
opt: {
  learning_rate: 0.001,
  epochs: 50,
  weight_decay: 0.05,
}
loader: {
  batch_size: 2,
}
train_cfg: {
  init_loss_norm: 200,
  clip_grad_l2norm: 1.0,
  cls_prior_prob: 0.01,
  center_sample: radius,
  center_sample_radius: 1.5,
  label_smoothing: 0.1,
  droppath: 0.1,
  loss_weight: -1, # 2.0 -1
}

# similar to THUMOS
test_cfg: {
  # vote operations to get better results
  voting_thresh: 0,
  pre_nms_topk: 3000,
  # max of predictions per video after nms, for fs, onlt 7 or 12 elements
  max_seg_num: 12,
  # less influence
  min_score: 0.005,
  # score fusion
  multiclass_nms: False,
  nms_sigma : 0.75,
  # file short segments
  duration_thresh: 0.001,
  cls_ignore: False,
}
output_folder: ./ckpt/fs1000/